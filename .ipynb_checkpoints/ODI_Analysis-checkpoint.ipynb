{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "# The dataset comes from  https://cricsheet.org/, and it is related to One Day Internation matches for all male players and it \n",
    "# is in the yaml format\n",
    "# The classification goal is to analyse the data only for India and Australia and to predict who win the Coming ODI between\n",
    "# Australia and India\n",
    "# The dataset can be downloaded from here - \"https://cricsheet.org/downloads/odis_male.zip\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "path =r'E:\\Hackathron\\India_VS_Australia\\odis_male' # use your path\n",
    "allFiles = glob.glob(path + \"/*.yaml\")\n",
    "\n",
    "list_ = []\n",
    "\n",
    "for file_ in allFiles:\n",
    "    with open(file_, 'r') as stream:\n",
    "        try:\n",
    "            ODI = yaml.load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "    if 'INDIA' in [x.strip().upper() for x in ODI['info']['teams']] and 'AUSTRALIA' in [x.strip().upper() for x in ODI['info']['teams']]:\n",
    "        team = []\n",
    "        batsman = []\n",
    "        bowler = []\n",
    "        batsman_runs = []\n",
    "        extra_runs = []\n",
    "        total_runs = []\n",
    "        fielder = []\n",
    "        outby = []\n",
    "        player_out = []\n",
    "        wicket = []\n",
    "        sixes = []\n",
    "        fours = []\n",
    "        innings = []\n",
    "        for i, j in enumerate(ODI['innings']):\n",
    "            for k in ODI['innings'][i]:\n",
    "                for l,m in enumerate(ODI['innings'][i][k]['deliveries']):\n",
    "                    for n in list(ODI['innings'][i][k]['deliveries'][l].keys()):\n",
    "                        innings.append(k)\n",
    "                        team.append(ODI['innings'][i][k]['team'])\n",
    "                        batsman.append(ODI['innings'][i][k]['deliveries'][l][n]['batsman'])\n",
    "                        bowler.append(ODI['innings'][i][k]['deliveries'][l][n]['bowler'])\n",
    "                        batsman_runs.append(ODI['innings'][i][k]['deliveries'][l][n]['runs']['batsman'])\n",
    "                        extra_runs.append(ODI['innings'][i][k]['deliveries'][l][n]['runs']['extras'])\n",
    "                        total_runs.append(ODI['innings'][i][k]['deliveries'][l][n]['runs']['total'])\n",
    "                        try:\n",
    "                            fielder.append(ODI['innings'][i][k]['deliveries'][l][n]['wicket']['fielders'][0])\n",
    "                            outby.append(ODI['innings'][i][k]['deliveries'][l][n]['wicket']['kind'])\n",
    "                            player_out.append(ODI['innings'][i][k]['deliveries'][l][n]['wicket']['player_out'])\n",
    "                            wicket.append(1)\n",
    "                        except:\n",
    "                            fielder.append(\"None\")\n",
    "                            outby.append(\"None\")\n",
    "                            player_out.append(\"None\")\n",
    "                            wicket.append(0)\n",
    "                        if ODI['innings'][i][k]['deliveries'][l][n]['runs']['batsman'] == 6:\n",
    "                            sixes.append(1)\n",
    "                        else:\n",
    "                            sixes.append(0)\n",
    "                        if ODI['innings'][i][k]['deliveries'][l][n]['runs']['batsman'] == 4:\n",
    "                            fours.append(1)\n",
    "                        else:\n",
    "                            fours.append(0)\n",
    "        ODI_International = {'Innings': innings,\n",
    "                        'Team': team,\n",
    "                        'Batsman': batsman,\n",
    "                        'Bowler': bowler,\n",
    "                        'Batsman_Runs': batsman_runs,\n",
    "                        'Extra_Runs': extra_runs,\n",
    "                        'Total_Runs': total_runs,\n",
    "                        'Fielder': fielder,\n",
    "                        'OutBy': outby,\n",
    "                        'Player_Out': player_out,\n",
    "                        'Wicket': wicket,\n",
    "                        'Sixes': sixes,\n",
    "                        'Fours': fours}\n",
    "        data = pd.DataFrame.from_dict(ODI_International)\n",
    "        df = data.groupby(['Innings','Team','Batsman','Bowler','OutBy','Fielder','Player_Out'],as_index=False).sum()\n",
    "        try:\n",
    "            df['City'] = ODI['info']['city']\n",
    "        except:\n",
    "            df['City'] = ODI['info']['venue'].split(\" \")[0]\n",
    "        df['Dates'] =  ODI['info']['dates'][0]\n",
    "        try:\n",
    "            df['Winner'] =  ODI['info']['outcome']['winner']\n",
    "        except:\n",
    "            df['Winner'] = \"No Result\"\n",
    "        try:\n",
    "            df['Man Of The Match'] = ODI['info']['player_of_match'][0]\n",
    "        except:\n",
    "            df['Man Of The Match'] = \"No One\"\n",
    "        df['Toss_Decision'] = ODI['info']['toss']['decision']\n",
    "        df['Toss_Winner'] =  ODI['info']['toss']['winner']\n",
    "        df['Venue'] =  ODI['info']['venue']\n",
    "        list_.append(df)\n",
    "        \n",
    "frame = pd.concat(list_, axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.to_excel(\"India_Australia_ODI.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets Import the necessary libraries\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RawDataSets = pd.read_excel(\"India_Australia_ODI.xlsx\")\n",
    "\n",
    "print(RawDataSets.shape)\n",
    "print(list(RawDataSets.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After converting the yaml data to dataframe we get 20 columns and 2859 rows, each row is the aggregation on categorical columns\n",
    "# and it represend each bowl score which is aggregated in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets check the data which we have extracted to get a hang of it\n",
    "\n",
    "RawDataSets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets discuss the input variuable, most of the variable are self explanatory, let discuss some\n",
    "# Batsman, bowler, outby, fielder and player out are some of the columns that are aggregated\n",
    "# For example - when batsman \"D Mongia\" is batting and he has faced bowler \"GD McGrath\" how many run he made, wicket and etc\n",
    "# so basically it's a aggregation of all the bowls faced by \"D Mongia\" when \"GD McGrath\" is bowling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict variable (desired target):\n",
    "# Winner — It is a categorical variable which holds the value of team name who has win the match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration\n",
    "# we see that the data is still not in the correct format for analysis, since some of the columns are increasing the rowns\n",
    "\n",
    "# so for our analysis purpose we will take the subset of data for answering the 1st questions winner of the series\n",
    "\n",
    "ODI_Outcome = RawDataSets.loc[:,['Innings', 'Team', 'Batsman_Runs', 'Extra_Runs', 'Total_Runs', 'Wicket',\n",
    "       'Sixes', 'Fours', 'City', 'Dates', 'Winner', 'Man Of The Match',\n",
    "       'Toss_Decision', 'Toss_Winner', 'Venue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this we need to aggregate the data based on below columns\n",
    "\n",
    "Aggre_ODI = ODI_Outcome.groupby(['Innings','Team','City','Dates','Winner','Man Of The Match','Toss_Decision','Toss_Winner','Venue'],as_index=False).sum()\n",
    "\n",
    "Aggre_ODI.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets see the data which we have aggregated above\n",
    "\n",
    "Aggre_ODI = Aggre_ODI.sort_values(by=['Dates','Innings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aggre_ODI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now to analyse each ODI matched we don't recquired bowl level information, so we will create a new data wits with only below columns:\n",
    "\n",
    "# we need to create a new column for innings and team\n",
    "\n",
    "Aggre_ODI[\"Team_Innings\"] = Aggre_ODI[\"Innings\"] +\"_\"+ Aggre_ODI[\"Team\"]\n",
    "\n",
    "ODI_Analysis = pd.get_dummies(Aggre_ODI[['Team_Innings']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have data in the format where if we aggregate we don't lose the innings information\n",
    "\n",
    "ODI_Analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets join the data with the original data and lets see if every thing is coming accurate\n",
    "\n",
    "ODI_Join = Aggre_ODI.join(ODI_Analysis)\n",
    "\n",
    "ODI_Join.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets remove the Innings , Team and Team_Innings column and then aggregate the data\n",
    "\n",
    "ODI_Final = ODI_Join.drop(columns=['Innings','Team','Team_Innings','Batsman_Runs','Extra_Runs','Total_Runs','Wicket','Sixes','Fours'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets aggreagte the data and see the final data\n",
    "\n",
    "Final_ODI = ODI_Final.groupby(['City','Dates','Winner','Man Of The Match','Toss_Decision','Toss_Winner','Venue'],as_index=False).sum()\n",
    "\n",
    "print(Final_ODI.shape)\n",
    "\n",
    "Final_ODI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have 43 rows which is the exact number of matched played by india and australia during 2006 to 2016\n",
    "# Now lets explore the data\n",
    "\n",
    "# lets visualize the dependent variable\n",
    "\n",
    "sns.countplot(x='Winner',data=Final_ODI, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will see who has won most of the times\n",
    "pd.DataFrame(Final_ODI.Winner.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that Our dependent variable are imbalanced, and the ratio of India winning to Australia is 32:53.\n",
    "\n",
    "# Before we go ahead to balance the dependent variable, let’s do some more exploration.\n",
    "\n",
    "# Now we will see how many times matches were played between india and australia in which city\n",
    "pd.DataFrame(Final_ODI.City.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will see what is the impact of toss decison on winning\n",
    "\n",
    "Winner_Toss = Final_ODI.groupby(\"Toss_Decision\").Winner.value_counts(normalize=True)\n",
    "\n",
    "pd.DataFrame(Winner_Toss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will visualise the able table using crossmatrix\n",
    "\n",
    "Winner_Toss.unstack()\n",
    "\n",
    "#  we see that when toss decision is bat the team wins most of the times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets analyse the venue odi played between india and australia\n",
    "\n",
    "pd.DataFrame(Final_ODI.groupby(\"City\").Venue.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see from the above venue, that nagpur has two cricket stadium with some what same name,\n",
    "# it may be because of the data discripency\n",
    "# But when we verified the data with the actual stadium we know that there are two stadium with this name, so the data is accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets see in which city india has won most of the time\n",
    "\n",
    "pd.crosstab(Final_ODI.City,Final_ODI.Winner).plot(kind='bar',figsize=(14,4))\n",
    "plt.title('Winning Frequency In City')\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Frequency of Winning')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that the frequescy of winning in city can be a good predictor\n",
    "# we see that in nagpur india has won most of the time and australia in chandigarh for india cities\n",
    "\n",
    "# now lets see the same for venue\n",
    "\n",
    "pd.crosstab(Final_ODI.Venue,Final_ODI.Winner).plot(kind='bar',figsize=(14,4))\n",
    "plt.title('Winning Frequency In Venue')\n",
    "plt.xlabel('Venue')\n",
    "plt.ylabel('Frequency of Winning')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets create additional column quarter from date column\n",
    "\n",
    "Final_ODI[\"Quarter\"] = Final_ODI[\"Dates\"].apply(lambda x: x.quarter)\n",
    "\n",
    "Final_ODI.sort_values(by=['Dates']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets see in which quarter india has won most of the time\n",
    "\n",
    "Winner_Quarter = Final_ODI.groupby(\"Quarter\").Winner.value_counts()\n",
    "\n",
    "Winner_Quarter.unstack()\n",
    "\n",
    "# We see that australia has won equal number of time in 1st and 4th quarter, and India has won most in 4th quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets model the the algorithm to predict who will win the series\n",
    "\n",
    "# So the first step is to convert the data into machine format\n",
    "\n",
    "# first we need to remove the data column\n",
    "\n",
    "ODI_Machine = Final_ODI.drop(columns='Dates')\n",
    "\n",
    "ODI_Machine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to create the dependent variable with value 0 and 1 for creating ML model\n",
    "\n",
    "# First we will remove the data with no result\n",
    "\n",
    "ODI_Machine = ODI_Machine.loc[ODI_Machine['Winner'] != 'No Result']\n",
    "\n",
    "print(ODI_Machine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will create a new column Prediction with values 0 and 1.\n",
    "# 0 will represend India and 1 will Represend Australia\n",
    "\n",
    "ODI_Machine[\"Winner_Y\"] = ODI_Machine['Winner'].apply(lambda x: 1 if x == 'Australia' else 0)\n",
    "\n",
    "ODI_Machine.loc[:,[\"Winner\",\"Winner_Y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will remove the winner column\n",
    "\n",
    "Final_Data = ODI_Machine.drop(columns=['Man Of The Match','Winner','Winner_Y','Team_Innings_1st innings_Australia','Team_Innings_2nd innings_Australia'])\n",
    "\n",
    "Final_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "# That is variables with only two values, zero and one.\n",
    "\n",
    "Machine_Data = pd.get_dummies(Final_Data, drop_first=True)\n",
    "\n",
    "print(Machine_Data.shape)\n",
    "print(list(Machine_Data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets join the dependend variable to the machine data\n",
    "\n",
    "Input_File = Machine_Data.join(ODI_Machine.Winner_Y)\n",
    "\n",
    "Input_File.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over-sampling using SMOTE\n",
    "# With our training data created, I’ll up-sample the India winning using the SMOTE algorithm(Synthetic Minority Oversampling Technique). At a high level, SMOTE:\n",
    "# Works by creating synthetic samples from the minor class (India) instead of creating copies.\n",
    "# Randomly choosing one of the k-nearest-neighbors and using it to create a similar, but randomly tweaked, new observations.\n",
    "# We are going to implement SMOTE in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Input_File.loc[:, Input_File.columns != 'Winner_Y']\n",
    "y = Input_File.loc[:, Input_File.columns == 'Winner_Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the SMOTE library\n",
    "from imblearn.over_sampling import SMOTE\n",
    "os = SMOTE(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature Scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_data_X,os_data_y=os.fit_sample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['Winner_Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can Check the numbers of our data\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of India winning in oversampled data\",len(os_data_y[os_data_y['Winner_Y']==0]))\n",
    "print(\"Number of Australia winning\",len(os_data_y[os_data_y['Winner_Y']==1]))\n",
    "print(\"Proportion of india winning data in oversampled data is \",len(os_data_y[os_data_y['Winner_Y']==0])/len(os_data_X))\n",
    "print(\"Proportion of australia data in oversampled data is \",len(os_data_y[os_data_y['Winner_Y']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a perfect balanced data! we have over-sampled only on the training data,\n",
    "# because by oversampling only on the training data, none of the information in the test data is being used to create\n",
    "# synthetic observations, therefore, no information will bleed from test data into the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination\n",
    "# Recursive Feature Elimination (RFE) is based on the idea to repeatedly construct a model and choose either the best or\n",
    "# worst performing feature, setting the feature aside and then repeating the process with the rest of the features. \n",
    "# This process is applied until all features in the dataset are exhausted. The goal of RFE is to select features by recursively\n",
    "# considering smaller and smaller sets of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final_vars=Input_File.columns.values.tolist()\n",
    "y=['Winner_Y']\n",
    "X=[i for i in data_final_vars if i not in y]\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, 20)\n",
    "rfe = rfe.fit(os_data_X, os_data_y.values.ravel())\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have get the final column for creating our model\n",
    "\n",
    "Column_Data = {'Col_Name': data_final_vars[:-1],\n",
    "              'Boolen_Val': rfe.support_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to convert the above into data frame so as to get the final columns\n",
    "\n",
    "Column_File = pd.DataFrame.from_dict(Column_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The RFE has helped us select the following features:\n",
    "\n",
    "Column_File['Col_Name'][Column_File['Boolen_Val'] == True].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=list(Column_File['Col_Name'][Column_File['Boolen_Val'] == True].values)\n",
    "X=os_data_X[cols]\n",
    "y=os_data_y['Winner_Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets implement the model\n",
    "# Logistic Regression Model Fitting\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set results and calculating the accuracy\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result is telling us that we have 4+3 correct predictions and 2+0 incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "from sklearn.externals import joblib\n",
    "filename = 'finalized_model.sav'\n",
    "joblib.dump(logreg, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "Odi_test = pd.read_excel(\"ODI_Test.xlsx\")\n",
    "result = loaded_model.predict(Odi_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So the above result shows that Australia will win the series with 4 out of 5 win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let us analyse who will be the Highest run scorer for the series\n",
    "\n",
    "# for this information we will be requiring the bowling and over data from the main datasets\n",
    "\n",
    "Batsman_MedianRun = RawDataSets.groupby(['Dates','Batsman'],as_index=False).Batsman_Runs.median()\n",
    "Batsman_Mean = RawDataSets.groupby(['Dates','Batsman'],as_index=False).Batsman_Runs.mean()\n",
    "Batsman_TotalRun = RawDataSets.groupby(['Dates','Batsman'],as_index=False).Batsman_Runs.sum()\n",
    "\n",
    "Batsman_MedianRun.sort_values(by=['Batsman_Runs'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batsman_TotalRun.sort_values(by=['Batsman_Runs'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batsman_Mean.sort_values(by=['Batsman_Runs'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that in all the case Rohit Sharma is the highest run scorer, with a consistant average of 28 runs\n",
    "\n",
    "# Next we have predict who will be the Highest wicket-taker\n",
    "\n",
    "# Bowler_MedianWicket = RawDataSets.groupby(['Dates','Bowler'],as_index=False).Wicket.median()\n",
    "# Bowler_MeanWicket = RawDataSets.groupby(['Dates','Bowler'],as_index=False).Wicket.mean()\n",
    "Bowler_TotalWicket = RawDataSets.groupby(['Dates','Bowler'],as_index=False).Wicket.sum()\n",
    "\n",
    "Bowler_TotalWicket.sort_values(by=['Wicket'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that there is a tie between the highest wicket taker, but since Ben is not playing this ODI, \n",
    "# we will go with Kane William Richardson for the highest wicket tacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let us analyse who will hit the maximun sixes in this odi\n",
    "\n",
    "Batsman_TotalSixes = RawDataSets.groupby(['Dates','Batsman'],as_index=False).Sixes.sum()\n",
    "\n",
    "Batsman_TotalSixes.sort_values(by=['Sixes'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batsman_MedianSixes = RawDataSets.groupby(['Dates','Batsman'],as_index=False).Sixes.median()\n",
    "\n",
    "Batsman_MedianSixes.sort_values(by=['Sixes'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above analysis we can safely say that Rohit Sharma will hit the maximum numer of sixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets see who will hit the maximun number of 4's in the series\n",
    "\n",
    "Batsman_TotalFour = RawDataSets.groupby(['Dates','Batsman'],as_index=False).Fours.sum()\n",
    "\n",
    "Batsman_TotalFour.sort_values(by=['Fours'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batsman_MedianFour = RawDataSets.groupby(['Dates','Batsman'],as_index=False).Fours.median()\n",
    "\n",
    "Batsman_MedianFour.sort_values(by=['Fours'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batsman_MeanFour = RawDataSets.groupby(['Dates','Batsman'],as_index=False).Fours.mean()\n",
    "\n",
    "Batsman_MeanFour.sort_values(by=['Fours'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above analysis for the number of 4's hit by any batsman, we find that though \"SR Tendulkar\" has the highest number\n",
    "# of sixes against Australia, but since he is retired we will not consider him in our result\n",
    "# The next second highest number of 4 hit by Virat Kholi, but we find that he is an outlier in this case, since his\n",
    "# Distribution of 4's runs is skewed to the right as the mean is greater than the median.\n",
    "# Finally the 3rd highets 4's hitter is Rohit Sharma  with a mean of 2.83 and median of 3 which tells that his distribution \n",
    "# is some what normal and we can safely bet on him for hitting the highest number of 4's in the series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
